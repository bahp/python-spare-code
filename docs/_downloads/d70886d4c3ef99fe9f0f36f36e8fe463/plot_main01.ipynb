{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Threshold moving\n\n .. note::  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Libraries scikits\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.datasets import load_iris\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import train_test_split\n\n\ndef display_npv_ppv_curve(ppv, npv, ths, idx):\n    \"\"\"This method plots the curve\n\n    Parameters\n    ----------\n    ppv: array-like\n    npv: array-like\n    ths: array-like\n    idx: integer\n    \"\"\"\n    # Display\n    f, axes = plt.subplots(1, 1)\n    axes.plot(ths, npv, marker='o', label='npv')\n    axes.plot(ths, ppv, marker='o', label='ppv')\n    axes.set(aspect='equal', xlim=[0,1], ylim=[0,1],\n        xlabel='threshold', title='th={0}, npv={1}, ppv={2}' \\\n            .format(round(ths[idx], 3),\n                    round(npv[idx], 3),\n                    round(ppv[idx], 3)))\n    plt.legend()\n\n\ndef npv_ppv_from_sens_spec(sens, spec, prev):\n    \"\"\"Compute npv and ppv.\n\n    Parameters\n    ----------\n    sens: array-like\n    spec: array-like\n    prev: float\n    \"\"\"\n    npv = (spec * (1 - prev)) / ((spec * (1 - prev)) + ((1 - sens) * prev))\n    ppv = (sens * prev) / ((sens * prev) + ((1 - spec) * (1 - prev)))\n    return npv, ppv\n\n\n\n# ----------------------\n# Load data\n# ----------------------\n# Fetch data\nX, y = fetch_openml(data_id=1464,\n                    return_X_y=True,\n                    as_frame=True)\n                    #parser='auto')\n\n# Format y to binary (0,1)\ny = y.cat.rename_categories({'1':0, '2':1})\n\n\n# Split\nX_train, X_test, y_train, y_test = \\\n    train_test_split(X, y, stratify=y)\n\n# ----------------------\n# Create pipeline\n# ----------------------\n# Create pipeline\nclf = make_pipeline(\n    StandardScaler(),\n    #LogisticRegression(random_state=0)\n    ExtraTreesClassifier(n_estimators=100)\n)\n\n# Train\nclf.fit(X_train, y_train)\n\n# Predictions\ny_pred = clf.predict(X_test)\ny_prob = clf.predict_proba(X_test)\n\n# .. note: Some classifiers do not have the decision\n#          function method but all implement the\n#          predict_proba.\n#y_score = clf.decision_function(X_test)\n\n# -----------------------\n# Show confusion matrix\n# -----------------------\n# .. note: We are using Display objects to plot\n#          the graphs, they could also be displayed\n#          using the functions or matplotlib\n#          directly.\n#\n# plot_roc_curve(clf, X_test, y_test, ax=ax_roc, name=name)\n# plot_det_curve(clf, X_test, y_test, ax=ax_roc, name=name)\n\n# Libraries\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import RocCurveDisplay\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import PrecisionRecallDisplay\n\n# Value counts\nvalue_counts = y.value_counts()\n\n# Prevalence\nprev = value_counts[1] / len(y_test)\n\n# Confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# .. note: It is possible to use either y_score\n#          or y_prob in the roc_curve function\n# .. note: sens=tpr, spec=1-fpr\n# Compute ROC curve\nfpr, tpr, ths1 = roc_curve(\n    y_test, y_prob[:, 1],\n    drop_intermediate=False)\n\n# .. note: ppv=prec, sens=recall\n# Compute PR curve\nprec, recall, ths2 = \\\n    precision_recall_curve(y_test, y_prob[:, 1])\n\n# Create plot objects\ncm_display = ConfusionMatrixDisplay(cm)\nroc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\npr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\n\n# Create figure\nf, axes = plt.subplots(1, 2, figsize=(12, 4))\naxes = axes.flatten()\n\n# Display\ncm_display.plot()\nroc_display.plot(ax=axes[0])\npr_display.plot(ax=axes[1])\n\n# Configure\nfor ax in axes:\n    ax.set(aspect='equal', xlim=[0,1], ylim=[0,1])\nplt.tight_layout()\n\n\n\n# ---------\n# Option I\n# ---------\n# Compute the npv and ppv from the sensitivity\n# and specificity values obtained from the\n# 'roc_curve' function.\n\n# Compute ROC curve\nfpr, tpr, ths1 = roc_curve(\n    y_test, y_prob[:, 1],\n    drop_intermediate=False)\n\n# Compute npv and ppv\nnpv, ppv = npv_ppv_from_sens_spec( \\\n    sens=tpr, spec=1-fpr, prev=prev)\n\n# Create DataFrame\nresults = pd.DataFrame(\n    data=np.array([ths1, ppv, npv, tpr, 1-fpr]).T,\n    columns=['th', 'ppv', 'npv', 'sens', 'spec']\n).sort_values(by='th')\n\n# Add gmean\nresults['gmean'] = np.sqrt(tpr * (1-fpr))\n\n# Find closest to 0.8\nidx = np.nanargmin(np.abs(npv - 0.8))\n\n# Find best gmean\nidx2 = np.argmax(results.gmean)\n\n# Display\ndisplay_npv_ppv_curve(ppv, npv, ths1, idx)\n\n# Title\nplt.suptitle(\"From 'roc_curve'\")\n\n# Show\nprint(\"\\n\\nResults from 'roc_curve'\")\nprint(results)\n\n\"\"\"\n# ---------\n# Option II\n# ---------\n# NOT WORKING!\n#\n# Compute the npv by knowing that it is the inverse\n# of the precision, thus calling the function\n# 'precision_recall_curve' with opposite labels and\n# probabilities.\n\n# .. note: invprec=npv\n# .. note: invrec=fnr\n# Computed inverted PR curve\ninvprec, invrec, invths2 = \\\n    precision_recall_curve(y_test, y_prob[:, 0],\n        pos_label=clf.classes_[0])\n\n# Create DataFrame\nresults = pd.DataFrame()\nresults['th'] = invths2[::-1]\nresults['npv'] = invprec[1:]\nresults['ppv'] = 0.0\nresults = results.sort_values(by='th')\n\n# Find closest to 0.8\nidx = np.nanargmin(np.abs(invprec - 0.8))\n\n# Show\nprint(\"\\n\\nResults from 'precision_recall_curve'\")\nprint(results)\nprint(\"\\nIndex: {0} | Threshold: {1} | NPV: {2}\" \\\n    .format(idx, invths2[idx-1], npv[idx]))\n\n# Display graph\ndisplay_npv_ppv_curve(\n    results.ppv,\n    results.npv,\n    results.th,\n    idx)\n\n# Title\nplt.suptitle(\"From 'precision_recall_curve'\")\n\"\"\"\n\n# ----------\n# Option II\n# ----------\n# Perform the computation of metrics and the threshold\n# search based on a condition (e.g. npv closest to an\n# specific value) manually.\n# Thresholds\nthresholds = np.linspace(0,1,100)\n\n# Metrics\ndef metrics(y_test, y_prob, th, **kwargs):\n    # Libraries\n    from sklearn.metrics import confusion_matrix\n    # Compute confusion matrix\n    cm = confusion_matrix(y_test, y_prob>th)\n    tn, fp, fn, tp = cm.ravel()\n    # Compute metrics\n    return {'th': th,\n            'ppv': tp/(tp+fp),\n            'npv': tn/(tn+fn),\n            'sens': tp/(tp+fn),\n            'spec': tn/(tn+fp)}\n\n# Compute scores\nscores = [metrics(y_test, y_prob[:,1], t) \\\n    for t in thresholds]\n\n# Create DataFrame\nresults = pd.DataFrame(scores)\n\n# Find idx where npv is closest to 0.8\nidx = np.nanargmin(np.abs(results.npv - 0.8))\n\n# Show\nprint(\"\\n\\nResults from manual\")\nprint(results)\n\n# Display graph\ndisplay_npv_ppv_curve(\n    results.ppv,\n    results.npv,\n    results.th,\n    idx)\n\n# Title\nplt.suptitle(\"From 'manual thresholds'\")\n\n# Show\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}