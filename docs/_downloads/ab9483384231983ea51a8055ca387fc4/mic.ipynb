{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# MIC package\n\nv1 = [R, R, R, R]\nv2 = [R, R, R, R]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Libraries\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.stats.contingency import crosstab\nfrom sklearn.metrics import mutual_info_score\n\n\ndef mutual_info_matrix_v3(x=None, y=None, ct=None):\n    \"\"\"Compute the component information score.\n\n    .. note: Might be inefficient but good for testing.\n\n    .. note: In order to be able to compute the mutual\n             information score it is necessary to have\n             variation within the variable. Thus, if\n             there is only one class, should we return\n             a result or a warning?\n\n    Parameters\n    ----------\n    x: list\n        List with the classes\n    y: list\n        List with the classes\n\n    Returns\n    -------\n    \"\"\"\n\n    def _check_nparray(obj, param_name):\n        if obj is not None:\n            if isinstance(obj, np.ndarray):\n                return obj\n            elif isinstance(obj, pd.Series):\n                return obj.to_numpy()\n            elif isinstance(obj, pd.DataFrame):\n                return obj.to_numpy()\n            elif isinstance(obj, list):\n                return np.array(obj)\n            else:\n                raise ValueError(\"\"\"\n                       The input parameter '{0}' is of type '{1} which is \n                       not supported. Please ensure it is a np.ndarray.\"\"\"\n                                 .format(param_name, type(obj)))\n\n        # Ensure they are all np arrays\n\n    x = _check_nparray(x, 'x')\n    y = _check_nparray(y, 'y')\n    ct = _check_nparray(ct, 'ct')\n\n    # Compute contingency\n    if ct is None:\n        c = crosstab(x,y)\n        if isinstance(c, tuple):\n            ct = c[-1]   # older scipy\n        else:\n            ct = c.count # newer scipy\n\n    # Variables\n    n = ct.sum()\n    pi = np.ravel(ct.sum(axis=1)) / n\n    pj = np.ravel(ct.sum(axis=0)) / n\n\n    # Create empty matrix\n    m = np.empty(ct.shape)\n    m[:] = np.nan\n\n    # Fill with component information score\n    with np.errstate(all='ignore'):\n        for i in range(m.shape[0]):\n            for j in range(m.shape[1]):\n                pxy = ct[i,j] / n\n                m[i,j] = pxy * np.log(pxy / (pi[i] * pj[j]))\n\n    # Fill with na (lim x->0 => 0)\n    m[np.isnan(m)] = 0\n\n    # Return\n    return m\n\n\ndef mutual_info_matrix_v2(x=None, y=None, ct=None):\n    \"\"\"Computes the component information.\n\n    The component information is calculated as below where X/Y\n    denotes a state (e.g. RR).\n\n        C(X/Y) = P(X/Y) * log(P(X/Y) / P(X)*P(Y))\n\n          c11 c12\n    C =   c21 c22\n\n    pi = [pi1, pi2]\n    pj = [pj1, pj2]\n\n    ci11 = c11/n * np.log(c11/n / pi1*pj1)\n    ci12 = c12/n * np.log(c12/n / pi1*pj2)\n    ci21 = c21/n * np.log(c21/n / pi2*pj1)\n    ci22 = c22/n * np.log(c22/n / pi2*pj2)\n\n    .. warning: It only works for square contingency matrices; that is, the\n                number of different classes appearing in the vectors x and y\n                must be the same.\n\n                Enough for susceptibility test with only R and S. Will\n                fail if only one is present or I is introduced.\n\n    Example\n    -------\n    sex           Female  Male  Total\n    lbl\n    Not Survived      89   483    572\n    Survived         230   112    342\n    Total            319   595    914\n\n    # Manual example.\n    ci11 = (89  / 914) * np.log((89  / 914) / (572 / 914) * (319 / 914))\n    ci12 = (483 / 914) * np.log((483 / 914) / (572 / 914) * (595 / 914))\n    ci21 = (230 / 914) * np.log((230 / 914) / (342 / 914) * (319 / 914))\n    ci22 = (112 / 914) * np.log((112 / 914) / (342 / 914) * (595 / 914))\n    m = np.array([[ci11, ci12], [ci21, ci22]])\n\n    # Compute\n    m = component_information_v0(x=data.lbl, y=d.sex)\n\n    Parameters\n    ----------\n\n    Returns\n    -------\n\n    \"\"\"\n\n    def _check_nparray(obj, param_name):\n        if obj is not None:\n            if isinstance(obj, np.ndarray):\n                return obj\n            elif isinstance(obj, pd.Series):\n                return obj.to_numpy()\n            elif isinstance(obj, pd.DataFrame):\n                return obj.to_numpy()\n            elif isinstance(obj, list):\n                return np.array(obj)\n            else:\n                raise ValueError(\"\"\"\n                       The input parameter '{0}' is of type '{1} which is \n                       not supported. Please ensure it is a np.ndarray.\"\"\"\n                                 .format(param_name, type(obj)))\n\n        # Ensure they are all np arrays\n\n    x = _check_nparray(x, 'x')\n    y = _check_nparray(y, 'y')\n    ct = _check_nparray(ct, 'ct')\n\n    # Compute contingency\n    if ct is None:\n        c = crosstab(x, y)\n        if isinstance(c, tuple):\n            ct = c[-1]  # older scipy\n        else:\n            ct = c.count  # newer scipy\n\n    with np.errstate(divide='ignore'):\n        # Variables\n        n = ct.sum()\n        pi = np.ravel(ct.sum(axis=1))\n        pj = np.ravel(ct.sum(axis=0))\n\n        # Compute matrix\n        b = np.repeat(pi.reshape(-1,1), len(pi), axis=1)\n        c = np.repeat(pj.reshape(1,-1), len(pj), axis=0)\n        m = (ct/n) * np.log((ct/n) / ((b/n) * (c/n)))\n\n    # Fill with na (lim x->0 => 0)\n    m[np.isnan(m)] = 0\n\n    # Return\n    return m\n\n\ndef mutual_info_matrix_v1(x=None, y=None, *, ct=None):\n    \"\"\"Computes the mutual information matrix\n\n    The component information is calculated as below where X/Y\n    denotes a state (e.g. RR).\n\n        C(X/Y) = P(XY) * log(P(XY) / P(X)*P(Y))\n               = P(XY) * [log(P(XY)) - log(P(X)*P(Y))]\n               = P(XY) * [log(P(XY)) - (log(P(X)) + log(P(Y)))]\n               = P(XY) * [log(P(XY)) - log(P(X)) - log(P(Y))]\n\n    .. note:: It is inspired by the code from sklearn.metrics.mutual_info_score.\n\n    Notes\n    -----\n    The logarithm used is the natural logarithm (base-e).\n    \"\"\"\n    from math import log\n    from scipy import sparse as sp\n    from sklearn.metrics.cluster._supervised import check_clusterings\n    from sklearn.metrics.cluster._supervised import check_array\n    from sklearn.metrics.cluster._supervised import contingency_matrix\n\n    labels_true, labels_pred, contingency = x, y, ct\n\n    if contingency is None:\n        labels_true, labels_pred = check_clusterings(labels_true, labels_pred)\n        contingency = contingency_matrix(labels_true, labels_pred, sparse=True)\n    else:\n        contingency = check_array(\n            contingency,\n            accept_sparse=[\"csr\", \"csc\", \"coo\"],\n            dtype=[int, np.int32, np.int64],\n        )\n\n    if isinstance(contingency, np.ndarray):\n        # For an array\n        nzx, nzy = np.nonzero(contingency)\n        nz_val = contingency[nzx, nzy]\n    elif sp.issparse(contingency):\n        # For a sparse matrix\n        nzx, nzy, nz_val = sp.find(contingency)\n    else:\n        raise ValueError(\"Unsupported type for 'contingency': %s\" % type(contingency))\n\n    contingency_sum = contingency.sum()\n    pi = np.ravel(contingency.sum(axis=1))\n    pj = np.ravel(contingency.sum(axis=0))\n\n    # Since MI <= min(H(X), H(Y)), any labelling with zero entropy, i.e. containing a\n    # single cluster, implies MI = 0\n    if pi.size == 1 or pj.size == 1:\n        return 0.0\n\n    log_contingency_nm = np.log(nz_val)\n    contingency_nm = nz_val / contingency_sum\n    # Don't need to calculate the full outer product, just for non-zeroes\n    outer = pi.take(nzx).astype(np.int64, copy=False) * \\\n            pj.take(nzy).astype(np.int64, copy=False) # b*c\n    log_outer = -np.log(outer) + np.log(pi.sum()) + np.log(pj.sum())\n\n    mi = (\n        contingency_nm * (log_contingency_nm - np.log(contingency_sum))\n        + contingency_nm * log_outer\n    )\n    mi = np.where(np.abs(mi) < np.finfo(mi.dtype).eps, 0.0, mi)\n\n    #return np.clip(mi.sum(), 0.0, None), mi\n    try:\n        return np.array(mi).reshape(contingency.shape).T\n    except:\n        return mi\n        #return mutual_info_matrix_v3(x=x, y=y, ct=ct)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}