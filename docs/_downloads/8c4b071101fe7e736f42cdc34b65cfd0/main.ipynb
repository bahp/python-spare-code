{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Main\n\nExample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import\nimport numpy as np\nimport pandas as pd\n\n# Specific\nfrom tpot import TPOTClassifier\n\n# Import own\nfrom pySML2.preprocessing.splitters import cvs_hos_split\nfrom pySML2.preprocessing.splitters import kfolds_split\n\n\n# ---------------------------------------------\n# Configuration\n# ---------------------------------------------\n# The input features and label for the algorithm\nfeatures = sorted(['alb', 'alp', 'alt', 'baso', 'bil', 'cl', 'cre', 'crp', 'egfr',\n                  'eos', 'k', 'ly',  'mcv', 'mono', 'mpv', 'nrbca', 'plt', 'rbc',\n                  'rdw',  'urea', 'wbc'])\n\n# The labels\nlabels = sorted(['micro_confirmed'])\n\n# The splits\nn_splits = 10\n\n# Dataset\n# -------\n# Dataset filepath\nfilepath = './dataset.csv'\n\n# ---------------------------------------------\n# Load dataset and format it\n# ---------------------------------------------\n# Read data\ndata = pd.read_csv(filepath)\ndata.columns = [c.lower() for c in data.columns.values]\n# data = data[features + labels]\n\n# Missing values\ndata['missing'] = data[features].isnull().sum(axis=1)\n\n# The indexes for complete profiles\ncmp = (data.missing == 0)\n\n# Split in CVS and HOS\ndata['cvs_hos_split'] = cvs_hos_split(data, selected_rows=cmp)\n\n# ---------------------------------------------\n# Train\n# ---------------------------------------------\ndata[(data.missing == 0)].to_csv('tpot_data_cvs.csv')\ndata[(data.cvs_hos_split == 'hos')].to_csv('tpot_data_hos.csv')\ndata[(data.cvs_hos_split == 'cvs')].to_csv('tpot_data_cvs.csv')\ndata[(data.cvs_hos_split == 'hos')].to_csv('tpot_data_hos.csv')\n\n# ---------------------------------------------\n# Train\n# ---------------------------------------------\n# The indexes used for cross validation\ncvs_idxs = (data.cvs_hos_split == 'cvs')\nhos_idxs = (data.cvs_hos_split == 'hos')\n\n# Create matrices train\nX_train = data[cvs_idxs][features].to_numpy()\ny_train = data[cvs_idxs][labels].to_numpy()\n\n# Create matrices test\nX_test = data[cvs_idxs][features].to_numpy()\ny_test = data[cvs_idxs][labels].to_numpy()\n\n# ---------------------------------------------\n# Search\n# ---------------------------------------------\n# Create genetic search\ntpot = TPOTClassifier(generations=5, verbosity=2,\n                      scoring='roc_auc', cv=2)\n\n# Fit\ntpot.fit(X_train, y_train)\n\n# Score\nscore = tpot.score(X_test, y_test)\n\n# Save\ntpot.export('tpot_best_pipeline.py')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}